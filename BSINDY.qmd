---
title: "Rapid Bayesian identification of sparse nonlinear dynamics from scarce and noisy data"
subtitle: NUMBAT Reading Group
date: 11 September 2025
bibliography: refs.bib
filter:
    - pyodide

format: 
    revealjs:
        html-math-method:
            method: mathjax
            url: https://cdn.jsdelivr.net/npm/mathjax@4/tex-chtml.js
        include-in-header:
            - text: |
                <script>
                window.MathJax = {
                    loader: {load: ['[tex]/physics']},
                    tex: {packages: {'[+]': ['physics']}}
                };
                </script>
        show-slide-number: all
---

## Summary

Source paper: @fung_rapid_2025

- SINDy is a method used to estimate dynamic models from data
- This paper presents a Bayesian reformulation of the method
- The Bayesian method is more robust against noise
- There are freaks out there that still use MatLab

## Background

Dynamic Models

These are an "old-world" model popular in applied mathematics. They aim to "explain" underlying mechanisms.

Typical presentation:

$$\frac{d}{dt} x(t) = f(t, x(t); \Theta)$$

. . . 

Can also be viewed as a nonlinear form of time-series regression:

$$
x_{t + \delta t} = x_t + \delta t \, f(t, x_t; \Theta)
$$

## Background

Usually, we use **domain knowledge** and **blind belief** to _specify_ $f$. For example, we might be observing a simple physical system, like a bouncing spring, where we have a good idea of the _governing equations_.

However, we sometimes have **complex systems** where we do not know exactly how the system behaves (or should behave).
Instead, we are interested in _discovering_ the governing equations from observations.

## SINDy

@brunton_discovering_2016 introduces a method for estimating a model $f$ from data $y$ under a _non-Bayesian_ control engineering framework.

The idea is that the mechanisms in $f$ can be represented as a **linear combination of simple library functions**.
Then, a **sparsity penalty** can be applied to shrink nuisance library functions to zero.

## A Running Example

The Van der Pol Oscillator

$$\begin{aligned}
\dot{x}_1 &= x_2\\
\dot{x}_2 &= -x_1 + 4x_2 - 4x_1^2x_2
\end{aligned}
$$

```{python}
#| label: comp-imports
import numpy as np
from numpy import typing as npt
from scipy import integrate, optimize
from matplotlib import pyplot as plt

import pysindy as pys
from bsindy_slides import van_der_pol

rng = np.random.default_rng(20250911)
```

## A Running Example

```{python}
plottable = van_der_pol.generate_solution()

fig, axs = plt.subplots(ncols=2)
axz = axs.flatten()
axz[0].plot(plottable.t, plottable.y.T)
axz[0].set_xlabel('t')
axz[0].legend(['$x_1$', '$x_2$'])

axz[1].plot(*plottable.y, color='k')
axz[1].set_xlabel('$x_1$')
axz[1].set_ylabel('$x_2$')

fig.set_layout_engine('tight')
_ = None
```

## A Running Example

We can view the (equations of the) Van der Pol oscillator as a linear combination of some library functions


$$
\begin{bmatrix} \dot{x}_1 \\ \dot{x}_2 \end{bmatrix} = 
\begin{bmatrix}
0 & 1 & 0 & 0 & 0 & \dots\\
-1 & 4 & 0 & -4 & 0 & \dots
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2 \\ x_1x_2 \\ x_1^2x_2 \\ x_1x_2^2 \\ \vdots
\end{bmatrix}
$$

And we aim to recover this matrix of coefficients.

## A Running Example: Vanilla SINDy

The method from @brunton_discovering_2016 is implemented in Python by the `pysindy` library:

```python
import pysindy

time = ...
data = ... + noise

# initialise w/ defaults
model = pysindy.SINDy() 

model.fit(data, t=time)

model.print()
```

. . . 

```{python}
model, data = van_der_pol.main(sparsity=van_der_pol.KINDA_DENSE, rng=rng)

model.print()
```

Truth:

$$\begin{aligned}
\dot{x}_1 &= x_2\\
\dot{x}_2 &= -x_1 + 4x_2 - 4x_1^2x_2
\end{aligned}
$$

## A Running Example: Vanilla SINDy

```{python}

model_sol = model.simulate(
    x0=data['observations'][:,0], 
    t=plottable.t
)

fig, axs = plt.subplots(ncols=2)
axz = axs.flatten()
axz[0].plot(data['truth'].t, data['observations'].T, 'x')
axz[0].set_prop_cycle(None) 
axz[0].plot(plottable.t, model_sol)

axz[1].plot(*data['observations'], 'x', color='r')
axz[1].plot(*model_sol.T, color='k')
```

## Emerging Problems 

1. That was quite a lot of data

    If we try again with less data:

## Emerging Problems
```{python}
sparse_model, sparse_data = van_der_pol.main(
    sparsity=van_der_pol.SPARSE,
    rng=rng,
)

sparse_model.print()
```

```{python}
sparse_model_sol = sparse_model.simulate(
    x0=sparse_data['observations'][:,0], 
    t=plottable.t
)

fig, axs = plt.subplots(ncols=2)
axz = axs.flatten()
axz[0].plot(sparse_data['truth'].t, sparse_data['observations'].T, 'x')
axz[0].set_prop_cycle(None) 
axz[0].plot(plottable.t, sparse_model_sol)

axz[1].plot(*sparse_data['observations'], 'x', color='r')
axz[1].plot(*sparse_model_sol.T, color='k')
```

## Emerging Problems

1. That was quite a lot of data

    If we try again with less data, we get worse results.

. . . 

2. We have no real measure of uncertainty in our estimate

## Existing Extensions and Solutions

- Ensemble SINDy

- SparseBayes

- 

## B-SINDy

Key contribution:




## References

::: {#refs}
:::